=pod

=head1 NAME

B<sally> - A tool for embedding strings in vector spaces

=head1 SYNOPSIS

B<sally> [B<options>] [B<-c> I<config>] I<input> I<output>

=head1 DESCRIPTION

B<sally> is a small tool for mapping a set of strings to a set of
vectors. This mapping is referred to as embedding and allows for
applying techniques of machine learning and data mining for analysis
of string data. B<sally> can be applied to several types of string data,
such as text documents, DNA sequences or log files, where it can
handle common formats such as directories, archives and text files of
string data.

The embedding of strings is carried out incrementally, where B<sally>
first loads a chunk of strings from I<input>, computes the mapping to
vectors and then writes the chunk of vectors to I<output>. The
configuration of this process, such as the input format, the embedding
setting and the output format, are specified in the file I<config> and
additionally using command-line options.

    .---------.                        .----------.
    |   dir   |                        |   text   |
    |   arc   |   \   .---------.   /  |  libsvm  |
    |  lines  |   --  |  Sally  |  --  |  matlab  |
    |   ...   |   /   '---------'   \  |   ...    |
    '---------'                        '----------'
      Input           Embedding          Output


B<sally> implements a standard technique for mapping strings to a vector
space that can be referred to as generalized bag-of-words model.  The
strings are characterized by a set of features, where each feature is
associated with one dimension of the vector space.  The following types of
features are supported by B<sally>: bytes, tokens, n-grams of bytes and
n-grams of tokens.

B<sally> proceeds by counting the occurrences of the specified
features in each string and generating a sparse vector of count
values.  Alternatively, binary or TF-IDF values can be computed and
stored in the vectors. B<sally> then normalizes the vector, for
example using the L1 or L2 norm, and outputs it in a specified format,
such as plain text, LibSVM, Cluto or Matlab format.

The processing chain of B<sally> makes use of sparse data structures,
such that high-dimensional vectors with millions of dimensions can be
handled efficiently.  All features are indexed by a hash function,
where the bit width of this function can be adjusted according to the
characteristics of the data.  In several settings, a hash width
between 22 and 26 bit already suffices to store millions of features
with little loss of accuracy.

=head1 CONFIGURATION

The configuration of B<sally> is specified in a configuration file.
This file is structured into the three sections B<input>, B<features>
and B<output>, which define the parameters of the input format, the
feature extraction and the output format, respectively.

All parameters of the configuration can be also be specified on the
command-line. That is, if a parameter is specified in the
configuration as B<xx = "yy">, it can be alternatively supplied as a
command-line option by B<--xx "yy">.

If no configuration file is provided, B<sally> resorts to a default
configuration. This default configuration can be dumped using the
command-line option B<-D>.

=head2 Input formats

B<sally> supports different formats for reading data sets of strings,
which may range from plain files to directories and other structured
resources. Following is a list of supported input formats.

=over 4

=item B<input = {>

=over 4

=item B<input_format = "lines";>

This parameter specifies the input format.

=over 14

=item I<"dir">

The input strings are available as binary files in a directory and the
name of the directory is given as I<input> to B<sally>. The suffixes
of the files are used as labels for the extracted vectors.

=item I<"arc">

The input strings are available as binary files in a compressed
archive, such as a zip or tgz archive.  The name of the archive is
given as I<input> to B<sally>.  The suffixes of the files are used as
labels for the extracted vectors.

=item I<"lines">

The input strings are available as lines in a text file. The name of the
file is given as I<input> to B<sally>.  The lines need to be separated by
newline and may not contain the NUL character.  Labels can be extracted from
each line using a regular expression (see B<lines_regex>).

=item I<"fasta">

The input strings are available in FASTA format. The name of the file is
given as I<input> to B<sally>.  Labels can be extracted from the description
of each sequence using a regular expression (see B<fasta_regex>).  Comments
are allowed if they are preceded by either ';' or '>'.

=item I<"stdin">

The input strings are read form standard input (stdin) as text lines. The
parameter I<input> is ignored.  The lines need to be separated by newline
and may not contain the NUL character.  Labels can be extracted from each
line using a regular expression (see B<lines_regex>).

=back

=item B<chunk_size = 256;>

To enable an efficient processing of large data sets, B<sally>
processes strings in chunks.  This parameter defines the number of
strings in one of these chunks. Depending on the lengths of the
strings, this parameter can be adjusted to balance loading and
processing of data.

=item B<decode_str = false;>

If this parameter is set to 1, B<sally> automatically decodes strings that
contain URI-encoded characters.  That is, substrings of the form %XX are
replaced with the byte represented by the hexadecimal number XX.  This
feature comes handy, if binary data is provided using the textual input
format "lines".  For example, HTTP requests can be stored in a single line
if line-breaks are represented by "%0a%0d".

=item B<fasta_regex = " (\\+|-)?[0-9]+";>

The FASTA format allows to equip each string with a short
description. In several data sets this description contains a
numerical label which can be useful in supervised learning tasks. The
parameter is a regular expression which can be used to match numerical
labels, such as +1 and -1.

=item B<lines_regex = "^(\\+|-)?[0-9]+";>

If the strings are available as text lines, the parameter can be used
to extract a numerical label from the start of the strings. The
parameter is a regular expression matching labels, such as +1 and -1.

=item B<reverse_str = false;>

If this parameter is set to 1, the bytes of all input strings will
be reversed. Such reversing might help in situations where the
reading direction of the input strings is unspecified.

=item B<stoptoken_file = "";>

Stop tokens (irrelevant words) can be filtered from the strings by providing
a file containing these tokens; one per line. Non-printable characters
can be escaped using URI encoding (%XX). Stop tokens can only be filtered, if
a set of delimiters is defined using B<token_delim>.

=back

=item B<};>

=back

=head2 Features

The strings loaded by B<sally> are characterized by a set of features,
where each feature is associated with one dimension of the vector
space. Different types of features can be extracted by changing the
following parameters.

=over 4

=item B<features = {>

=over 4

=item B<ngram_len = 2;>

=item B<granularity = "bytes";>

The parameter B<ngram_len> specifies the numbers of consecutive symbols that
are considered as one feature, while the parameter B<granularity> defines the
granularity of these symbols.  If the granularity is set to I<bytes>,
B<sally> considers bytes as symbols, whereas if B<granularity> is set to
I<tokens>, all strings (token) separated by a set of delimiters are
considered as symbols.  The following types of different feature types can
be extracted using these parameters:

=over 14

=item I<tokens>

The strings are partitioned into substrings (tokens) using a set of
delimiter characters.  Such partitioning is typical for natural language
processing, where the delimiters are usually defined as white-space and
punctuation symbols.  An embedding using tokens is selected by choosing
I<tokens> as granularity (B<granularity>), defining a set of delimiter
characters (B<token_delim>) and setting the n-gram length to 1
(B<ngram_len>).

=item I<byte n-grams>

The strings are characterized by all possible byte sequences of a fixed
length n (byte n-grams).  These features are frequently used if no
information about the structure of strings is available, such as in
bioinformatics or computer security.  An embedding using byte n-grams is
selected by choosing I<bytes> as granularity (B<granularity>) and defining
the n-gram length (B<ngram_len>).

=item I<token n-grams>

The strings are characterized by all possible token sequences of a fixed
length n (token n-grams).  These features require the definition of a set of
delimiters and a length n.  They are often used in natural language
processing as a coarse way for capturing structure of text.  An embedding
using token n-grams is selected by choosing I<tokens> as granularity
(B<granularity>), defining a set of delimiter characters (B<token_delim>) and
choosing an n-gram length (B<ngram_len>).

=back

=item B<token_delim = " %0a%0d";>

The parameter B<token_delim> defines characters for delimiting tokens in
strings, for example I<" %0a%0d">.  It is only considered, if the
granularity is set to I<tokens>, otherwise it is ignored.

=item B<ngram_pos = false;>

=item B<pos_shift = 0;>

The parameter B<ngram_pos> can be used to enable positional n-grams. In
contrast to regular n-grams, these substrings of length n are associated
with a position in the originating string.  Positional n-grams thus only
match if they appear at the same location in a string.  The additional
parameter B<pos_shift> can be used to add a shift to the n-grams.  If the
parameter is set to I<k>, multiple positional n-grams are extracted with a
shift from I<-k> to I<+k>.

=item B<ngram_blend = false;>

The parameter B<ngram_blend> can be used to enable blended n-grams. In this
setting, n-grams starting from length 1 up to length B<ngram_len> are
extracted and used for creating a feature vector.  That is, all n-gram
lengths are blended in a joint feature vector, hence the name of this
approach.

=item B<ngram_sort = false;>

This parameter can be used to enable sorted n-grams (n-perms). During the
extraction of an n-gram its symbols are sorted according to their
lexographical order. That is, if n-grams are composed of bytes, these bytes
are sorted. If the n-grams are composed of tokens, the respective tokens are
sorted. Sorted n-grams can be used to compensate minor perturbation in
string data. For example, the strings "abac" and "aabc" contain the same
sorted 3-grams, namely "aab" and "abc".

=item B<vect_embed = "bin";>

This parameter specifies how the features are embedded in the vector
space. Supported values are "bin" for associating each dimension with
a binary value, "cnt" for associating each dimension with a count
value and "tfidf" for using a TF-IDF weighting.

=item B<vect_norm = "none";>

The feature vectors extracted by B<sally> can be normalized to a given
vector norm. Supported norms are "l1" for the Taxicab norm (L1) and
"l2" for the Euclidean norm (L2). Normalization is often useful, if
the lengths of the strings varies significantly and thus vectors
differ just due to the number of extracted features.

=item B<vect_sign = false;>

B<sally> uses a hash function to map individual features to dimensions in
the vector space.  Depending on the number of bits used by this functions,
different features may collide on the same dimension.  Such collisions often
result in larger values at these dimensions.  The parameter B<vect_sign> can
be used to enable a signed embedding.  That is, one bit of the hash function
is used to define a sign for each feature.  Collisions are still possible,
yet their impact is lessened as colliding features not necessary induce
larger values.

=item B<thres_low = 0;>

This parameter defines a minimum threshold for the entries in each vector.
Values below the threshold are removed.  The parameter can be used to filter
low-valued features from the vectors, such as very infrequent tokens.
If the parameter is set to 0, the thresholding is disabled.

=item B<thres_high = 0;>

This parameter defines a maximum threshold for the entries in each vector.
Values above the threshold are removed.  The parameter can be used to filter
high-valued features from the vectors, such as very frequent tokens.
If the parameter is set to 0, the thresholding is disabled.

=item B<hash_bits = 22;>

B<sally> uses a hash function to map individual features to dimensions.
This parameter specifies the number of bits used by this hash function and
defines the maximum dimensionality of the vector space with 2 ** bits.  As
the embedding of B<sally> is usually sparse and only a small fraction of
dimensions is non-zero, 22 to 26 bits are often sufficient for representing
the data.  If this parameter is chosen too small, the embedding may suffer
from collisions of features in the vector space.  If it is chosen too large,
several application may choke from the vast amount of dimensions.

=item B<explicit_hash = false;>

For performance reasons B<sally> maps features to dimensions without
memorizing the features associated with these dimensions.  For certain
analysis tasks, however, it may be necessary to retrieve a full mapping
including the features of each dimension.  If this parameter is enabled
B<sally> keeps track of all features and depending on the selected output
format stores them with the extracted feature vectors.  The mapping may
suffer from collisions due to hashing.  You can control the size of the
hash table using the parameter B<hash_bits>.

=item B<hash_file = "";>

This parameter enables saving the mapping between features and dimensions to
a gzip-compressed file.  The functionality is similar to B<explicit_hash>,
except that B<sally> does not store the features with the feature vectors
but separately in a file.  Note that the tracking of features and dimensions
induces a considerable performance overhead.  Also note that mapping may
contain collisions, where simply the latest colliding entry overrides
previous entries.  You can control the size of the hash table using the
parameter B<hash_bits>.

=item B<tfidf_file = "tfidf.fv";>

This parameter specifies a file to store the TF-IDF weights. If the
embedding B<tfidf> is selected, B<sally> first checks if the given
file is present. If it is not available, TF-IDF weights will be
computed from the input data and stored to this file, otherwise the
weights will be read from the file. Keeping a separate file for TF-IDF
weights allows for computing the weighting for a data set, say the
training set, and applying the exact same weighting to further data
sets.

=back

=item B<};>

=back

=head2 Filtering and dimension reduction

B<sally> supports some simple methods for unsupervised filtering and
dimension reduction.  These can be applied to reduce the number of
dimensions in the feature vectors.  Due to their simplicitiy, however, these
methods only capture a small amount of information from the original feature
vectors and should be used with caution.

=over 4

=item B<filter = {>

=over 4

=item B<dim_reduce = "none";>

Following is a list of methods for unsupervised filtering and dimension
reduction supported by B<sally>:

=over 14

=item I<"none">

No dimension reduction is performed.

=item I<"simhash">

Each feature vector is reduced to a similarity hash with B<dim_num> bits.
The string features associated with each dimension are hashed and aggregated
to a single hash value as proposed by Charikar (STOC 2002).  For
convenience, the computed hash value is again represented as a feature
vector.  Note that the number of maximum bits is defined by B<hash_bits> in
the feature configuration section.

=item I<"minhash">

Each feature vector is reduced to a "minimum hash" with B<dim_num> bits. The
string features associated with each dimension are hashed and sorted
multiple times as proposed by Broder (1997).  In each round the smallest
hash value is appended to the minimum hash.  The number of hash bits in each
round is defined by B<hash_bits> in the feature configuration section and
the number of rounds is simply determined by ceil(B<dim_num> /
B<hash_bits>).


=item I<"bloom">

Each feature vector is reduced to a small Boom filter with B<dim_num> bits.
The string features associated with each dimension are hashed using
B<bloom_num> hash functions.  For each string feature and each hash function
one bit in the filter is set.  As a result, the filter is populated with
bits similar to a real Bloom filter.  To avoid saturating the filter,
B<dim_num> should be significantly larger than B<bloom_num> if several
string features are associated with one feature vector.  As a rule of thumb
you can set B<bloom_num> = 0.7 * B<dim_num> / I<vec_len>, where I<vec_len>
is the expected number of string features.

=back

=item B<dim_num = 32;>

This parameter defines the number of dimensions/bits to generate using
unsupervised dimension reduction.

=item B<bloom_num = 2;>

This parameters specifies how many hash functions are used to map a feature
vector and its string features to a Bloom filter.  To avoid saturating the
filter, you should choose B<bloom_num> significantly smaller than the size
of the Bloom filter B<dim_num>.

=back

=item B<};>

=back

=head2 Output formats

Once the input strings have been embedded in a vector space, B<sally>
stores the resulting vectors in one of several common formats, which
allows for applying typical tools of statistics and machine learning
to the data, for example, Matlab, Octave, Shogun, Weka, SVMLight and
LibSVM.

=over 4

=item B<output = {>

=over 4

=item B<output_format = "libsvm";>

Following is a list of output formats supported by B<sally>:

=over 14

=item I<"libsvm">

The feature vectors of the embedded strings are stored in the common
libsvm format, which is supported by Shogun, SVMLight and LibSVM. The
name of the output file is given as I<output> to B<sally>.

=item I<"text">

The feature vectors of the embedded strings are stored as plain text.
Each feature vector is represented as a list of dimensions, which is written
to I<output> in the following form

    dimension:feature:value,... source

I<dimension> specifies the index of the dimension, I<feature> a textual
representation of the feature and I<value> the value at the dimension.  If
parameter B<explicit_hash> is not enabled in the configuration, the field
I<feature> is empty.

=item I<"stdout">

The feature vectors of the embedded strings are written to standard output
(stdout) as text.  Each feature vector is represented as a list of
dimensions in the following form:

    dimension:feature:value,... source

I<dimension> specifies the index of the dimension, I<feature> a textual
representation of the feature and I<value> the value at the dimension.  If
parameter B<explicit_hash> is not enabled in the configuration, the field
I<feature> is empty.

=item I<"matlab">

The feature vectors of the embedded strings are stored in Matlab
format (v5).  The vectors are stored as a 1 x n struct array with the
fields: data, src, label and feat. The name of the output file is
given as I<output> to B<sally>. Note that great care is required to
efficiently operate with sparse vectors in Matlab. If the sparse
representation is lost during computations, excessive run-time and
memory requirements are likely.

=item I<"cluto">

The feature vectors of the embedded strings are stored as a sparse
matrix suitable for the clustering tool Cluto. The first line of
the file is a header for Cluto, while the remaining lines correspond
to feature vectors. The name of the output file is given as I<output>
to B<sally>. Note that Cluto can not handle arbitrarily large vector
spaces and thus the B<"hash_bits"> should be set to values below 24.

=item I<"json">

The feature vectors of the embedded strings are stored as JSON objects.
Each object contains a list of dimension indices denoted I<dim> and
corresponding values denoted as I<val>.  Depending on the configuration the
source for each object as well as the actual string feature associated with
each dimension are also stored in the JSON object.

=back

=item I<skip_null = false;>

If this parameter is enabled, B<sally> will not output null vectors, that
is, vectors where all dimensions are zero.  These vectors occur if a string
does not contain a single string feature.

=back

=item B<};>

=back

=head1 OPTIONS

The configuration of B<sally> can be refined and altered using several
command-line options. In particular, all parameters of the
configuration can be specified on the command-line. That is, if a
parameter is specified as B<xx = "yy"> in the configuration file, it
can be changed by using the command-line option B<--xx
"zz">. Following is a list of common options:

=head2 I/O options

  -i,  --input_format <format>   Set input format for strings.
       --chunk_size <num>        Set chunk size for processing.
       --decode_str              Enable URI-decoding of strings.
       --fasta_regex <regex>     Set RE for labels in FASTA data.
       --lines_regex <regex>     Set RE for labels in text lines.
       --reverse_str             Reverse (flip) all strings.
       --stoptoken_file <file>   Provide a file with stop tokens.
  -o,  --output_format <format>  Set output format for vectors.
  -k,  --skip_null               Skip null vectors in output.

=head2 Feature options

  -n,  --ngram_len <num>         Set length of n-grams.
  -d,  --token_delim <delim>     Set delimiters of tokens.
  -g   --granularity <type>      Set granularity: bytes, tokens.
  -p,  --ngram_pos               Enable positional n-grams.
       --pos_shift <num>         Set shift of positional n-grams.
  -B,  --ngram_blend             Enable blended n-grams.
  -s,  --ngram_sort              Enable sorted n-grams (n-perms).
  -E,  --vect_embed <embed>      Set embedding mode for vectors.
  -N,  --vect_norm <norm>        Set normalization mode for vectors.
  -S,  --vect_sign               Enabled signed embedding.
       --thres_low <float>       Enable minimum threshold for vectors.
       --thres_high <float>      Enable maximum threshold for vectors.
  -b,  --hash_bits <num>         Set number of hash bits.
  -X,  --explicit_hash           Enable explicit hash table.
       --hash_file <file>	 Set file name for explicit hash table.
       --tfidf_file <file>       Set file name for TFIDF weighting.

=head2 Generic options

  -c,  --config_file <file>      Set configuration file.
  -v,  --verbose                 Increase verbosity.
  -q,  --quiet                   Be quiet during processing.
  -C,  --print_config            Print the current configuration.
  -D,  --print_defaults          Print the default configuration.
  -V,  --version                 Print version and copyright.
  -h,  --help                    Print this help screen.

=head1 FILES

=over 4

=item F<PREFIX/share/doc/sally/example.cfg>

An example configuration file for B<sally>. See the configuration
section for further details.

=back

=head1 COPYRIGHT

Copyright (c) 2010-2013 Konrad Rieck (konrad@mlsec.org);
		Christian Wressnegger (christian@mlsec.org);
		Alexander Bikadorov (abiku@cs.tu-berlin.de)

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation; either version 3 of the License, or (at
your option) any later version.  This program is distributed without
any warranty. See the GNU General Public License for more details.
=cut
